{
  "articles": [
    {
      "path": "404.html",
      "title": "404 Error",
      "author": [],
      "contents": "\r\nYou may have reached this page in error. Please return to the home page, or open an issue on our GitHub repository.\r\n\r\n\r\n\r\n",
      "last_modified": "2021-07-16T11:49:14-07:00"
    },
    {
      "path": "index.html",
      "title": "Systematic Review of Human Postmortem Immunohistochemical Studies and Bioinformatics Analyses Unveil the Complexity of Astrocyte Reaction in Alzheimerâ€™s Disease",
      "description": "We performed a systematic review of the neuropathological literature followed by bioinformatics analyses to reveal the complexity of AD reactive astrogliosis.\n",
      "author": [],
      "contents": "\r\n\r\nContents\r\nDependencies\r\nDocumentation\r\nCode Availability\r\n\r\nDependencies\r\nTo run our code, please install the R programming language and statistical computing environment (version 4.1.0). Additional required libraries are specified in each script.\r\n\r\nDocumentation\r\nTo read our documented code, please visit www.serranopozolab.org/astrocyte-review.\r\nCode Availability\r\nOur full codebase is available for download on GitHub.\r\n\r\n\r\n\r\n",
      "last_modified": "2021-07-16T11:49:16-07:00"
    },
    {
      "path": "network-analysis.html",
      "title": "PPI Network Analysis",
      "description": "This script constructs a protein-protein interaction network using the STRING database and visualizes the network via several plots.\n",
      "author": [
        {
          "name": {},
          "url": "https://www.github.com/ayushnoori"
        }
      ],
      "contents": "\r\n\r\nContents\r\nDependencies\r\nQuery STRING API\r\nConstruct PPI Network\r\nCalculate Assortativity Coefficient\r\nDefine Color Palette\r\nPlot Heatmap\r\nCalculate Centrality Scores\r\nPlot Circos Graph\r\nPlot Chord Graph\r\nPlot Network Graph\r\nHub Gene Networks\r\nInteractive Network Graph\r\n\r\nDependencies\r\nLoad requisite packages and define directories. Note that the GitHub package mattflor/chorddiag is used to create interactive chord diagrams using the Javascript visualization library D3. This package can be downloaded via devtools::install_github(\"mattflor/chorddiag\").\r\nThis script also uses my personal utilities package brainstorm, which can be downloaded via devtools::install_github(\"ayushnoori/brainstorm\").\r\n\r\n\r\n# data manipulation\r\nlibrary(data.table)\r\nlibrary(purrr)\r\nlibrary(magrittr)\r\n\r\n# fast file system operations\r\nlibrary(fs)\r\n\r\n# access STRING API\r\nlibrary(httr)\r\n\r\n# base visualization\r\nlibrary(ggplot2)\r\nlibrary(RColorBrewer)\r\n\r\n# graph libraries\r\nlibrary(igraph)\r\nlibrary(ggraph)\r\nlibrary(graphlayouts)\r\n\r\n# heatmap\r\nlibrary(ComplexHeatmap)\r\n\r\n# chord diagrams\r\nlibrary(circlize)\r\nlibrary(chorddiag)\r\n\r\n# interactive network\r\nlibrary(visNetwork)\r\n\r\n# utility functions\r\nlibrary(brainstorm)\r\n\r\n\r\n\r\nNote that directories are relative to the R project path.\r\n\r\n\r\n# set directories\r\nddir = \"Data\"\r\ndir1 = file.path(\"Results\", \"1 - STRING PPI Network\")\r\n\r\n\r\n\r\nQuery STRING API\r\nRead data, then count the number of input proteins.\r\n\r\n\r\n# read data\r\ndat = fread(file.path(ddir, \"ADRA Protein Set.csv\"), encoding = \"UTF-8\")\r\nnrow(dat) %>% paste0(\"Input Proteins: \", .) %>% message\r\n\r\n# show data\r\nshow_table(head(dat, 20))\r\n\r\n\r\n\r\nSTRING is a database of known and predicted protein-protein interactions which allow the creation of functional protein association networks [1].\r\nMap from gene symbols to STRING IDs using the STRING API. Proteins whose preferred IDs differ from their query symbol are later replaced before the network is constructed [2,3]. As expected, the immunoglobulins are excluded as they are not represented in the STRING database.\r\n\r\n\r\nroot_api = \"https://version-11-0b.string-db.org/api\"\r\n\r\n# construct query URL\r\nmap_symbols = list(identifiers = paste(dat[, Symbol], collapse=\"%0d\"),\r\n                   species = \"9606\", echo_query = \"1\", caller_identity = \"SerranoPozoLab\")\r\n\r\n# complete API call to map IDs\r\nid_request = httr::POST(url = paste0(root_api, \"/tsv/get_string_ids\"), body = map_symbols)\r\nids = httr::content(id_request, as = \"text\", encoding = \"UTF-8\") %>% fread()\r\n\r\n# check for multiple mappings\r\nids[, any(duplicated(queryIndex))] %>% paste0(\"Multiple Mappings: \", ., \"\\n\") %>% message()\r\n\r\n# check for duplicate mappings\r\ndiff = ids[queryItem != preferredName]\r\ndiff[, paste(queryItem, preferredName, sep = \" --> \")] %>%\r\n  c(\"Different Mappings: \", .) %>% paste0(\"\\n\") %>% message()\r\n\r\n# count total proteins with mappings\r\nnrow(ids) %>% paste0(\"Proteins with Mappings: \", ., \"/\", nrow(dat), \"\\n\") %>% message()\r\n\r\n# print excluded proteins\r\ndat[!(Symbol %in% ids$queryItem), paste(Symbol, collapse = \", \")] %>%\r\n  paste0(\"Excluded Markers: \", .) %>% message()\r\n\r\n\r\n\r\nConstruct the network using another API call. Note that, as above, we use a POST request rather than the simpler GET to circumvent the character limit of the latter. KIF21B is excluded as it is an isolated node (does not have any connections).\r\n\r\n\r\n# construct query URL\r\nget_network = list(identifiers = paste(ids[, stringId], collapse=\"%0d\"),\r\n                   species = \"9606\", echo_query = \"1\", caller_identity = \"SerranoPozoLab\")\r\n\r\n# complete API call to retrieve network\r\nnetwork_request = httr::POST(url = paste0(root_api, \"/tsv/network\"), body = get_network)\r\nnetwork = httr::content(network_request, as = \"text\", encoding = \"UTF-8\") %>% fread()\r\n\r\n# count total included proteins\r\nnetwork[, c(preferredName_A, preferredName_B)] %>% uniqueN() %>%\r\n  paste0(\"Proteins Included in Network: \", ., \"/\", nrow(dat), \"\\n\") %>% message()\r\n\r\n# print excluded proteins\r\nnetwork[, c(preferredName_A, preferredName_B)] %>% \r\n  c(diff$queryItem, .) %>%\r\n  { dat[!(Symbol %in% .), paste(Symbol, collapse = \", \")] } %>%\r\n  paste0(\"Excluded Markers: \", .) %>% message()\r\n\r\n\r\n\r\nConstruct PPI Network\r\nUse igraph functions to create the network. Proteins whose preferred IDs differ from their query symbol are replaced before the network is constructed. Note that the complete dat object, including the markers IGHA1, IGHG1, IGHM, and KIF21B (which have no connections), is passed to the graph_from_data_frame call; hence, while these nodes will be included in the vertex list of the network object, they will have a centrality of 0 and will not be present when visualizing the network.\r\n\r\n\r\n# remove unneeded columns and duplicate rows\r\nnetwork[, c(\"stringId_A\", \"stringId_B\", \"ncbiTaxonId\") := NULL]\r\nnetwork = unique(network)\r\n\r\n# replace with correct query symbols\r\nreplace_diff = function(net, r, pname, qname) { net[get(r) == pname, (r) := qname] }\r\npwalk(diff[, .(preferredName, queryItem)], ~replace_diff(network, \"preferredName_A\", .x, .y))\r\npwalk(diff[, .(preferredName, queryItem)], ~replace_diff(network, \"preferredName_B\", .x, .y))\r\nsetnames(network, old = 1:2, c(\"nodeA\", \"nodeB\"))\r\n\r\n# construct network\r\nsetcolorder(dat, \"Symbol\")\r\nnet = graph_from_data_frame(d = network, vertices = dat, directed = FALSE)\r\n\r\n# show network\r\nshow_table(head(network, 20))\r\n\r\n\r\n\r\nBelow is a key of column names which represent evidence for interaction in the STRING database.\r\nName\r\nDefinition\r\nscore\r\ncombined score\r\nnscore\r\ngene neighborhood score\r\nfscore\r\ngene fusion score\r\npscore\r\nphylogenetic profile score\r\nascore\r\ncoexpression score\r\nescore\r\nexperimental score\r\ndscore\r\ndatabase score\r\ntscore\r\ntext mining score\r\nCalculate Assortativity Coefficient\r\nThe assortativity coefficient is positive is similar vertices - based on some external property, in this case, we use functional category - tend to connect to each other, and negative otherwise.\r\n\r\n\r\n# calculate assortativity\r\nassort = V(net)$Group %>% as.factor() %>% as.integer() %>% assortativity_nominal(net, ., directed = FALSE)\r\nmessage(paste(\"Assortativity Coefficient:\", assort))\r\n\r\n\r\n\r\nDefine Color Palette\r\nFirst, define the color palette for all subsequent plots.\r\n\r\n\r\n# define color palette\r\ncols = colorRampPalette(c(\"#B4436C\", \"#F2BAC9\", \"#F7A278\", \"#FCEFB4\", \"#C8E9A0\", \"#6DD3CE\", \"#91A6FF\", \"#E5C2FF\", \"#B49082\", \"#ABB8C4\"))(uniqueN(dat[, Group]))\r\n\r\n# set names and order\r\nnames(cols) = dat[, Group] %>% unique() %>% .[order(.)]\r\n\r\n# set alternating order for chord diagram\r\nalt = dat[, .N, by = Group] %>% .[order(Group), N] %>% order()\r\nalt = c(rbind(alt[1:9], rev(alt[10:18])))\r\n\r\n# set order for chord diagram\r\n# alt = dat[, .N, by = Group] %>% .[order(Group), N] %>% order()\r\n\r\n\r\n\r\nPlot Heatmap\r\nPlot a heatmap of the adjacency matrix. Cluster rows and columns and annotate by functional group.\r\n\r\n\r\n# extract adjacency matrix\r\nhm_dat = as_adj(net, attr = \"score\", sparse = FALSE)\r\ndiag(hm_dat) = 1\r\n\r\n# create heatmap annotations\r\nhm_annos = dat[, Group]\r\nhm_cols = list(Group = cols)\r\n\r\n# create group labels, add line breaks\r\nhm_grp = unique(hm_annos)\r\nhm_grp[c(2, 3, 7, 8, 18)] = c(\"Blood-Brain\\nBarrier\", \"Calcium\\nHomeostasis\", \"Insulin\\nSignaling\", \"Intracellular\\nTrafficking\", \"Water/K+\\nHomeostasis\")\r\n\r\n# top annotation\r\ntop_annos = HeatmapAnnotation(Group = anno_block(gp = gpar(fill = cols),\r\n                                                 labels = hm_grp,\r\n                                                 labels_gp = gpar(fontsize = 7, lineheight = 0.8)))\r\n\r\n# left annotation\r\nleft_annos = rowAnnotation(Group = anno_block(gp = gpar(fill = cols),\r\n                                              labels = hm_grp,\r\n                                              labels_gp = gpar(fontsize = 7, lineheight = 0.8)))\r\n\r\n# function to set outline of each functional group\r\ngroup_outline = function(j, i, x, y, width, height, fill) {\r\n  if(i[1] == j[1]) grid.rect(gp = gpar(lwd = 2, fill = \"transparent\"))\r\n}\r\n\r\n# function to establish color scale\r\ncolor_scale = function(maxcol, val) { colorRamp2(c(0, 1), c(\"#F3F4F7\", maxcol))(val) }\r\n\r\n# function to set color of each cell, darker color is #9DA5BE\r\ncolor_cell = function(j, i, x, y, width, height, fill) {\r\n  if(hm_annos[i] == hm_annos[j]) {\r\n    grid.rect(x = x, y = y, width = width, height = height,\r\n              gp = gpar(col = NA, fill = color_scale(cols[hm_annos[i]], hm_dat[i, j])))\r\n  } else {\r\n    grid.rect(x = x, y = y, width = width, height = height,\r\n             gp = gpar(col = NA, fill = color_scale(\"#525C7A\", hm_dat[i, j])))\r\n  }\r\n}\r\n\r\n# plot heatmap\r\nhm = Heatmap(hm_dat,\r\n             col = c(\"#F3F4F7\", \"red\"),\r\n             row_split = hm_annos, column_split = hm_annos,\r\n             cluster_row_slices = FALSE, cluster_column_slices = FALSE,\r\n             row_gap = unit(1, \"mm\"), column_gap = unit(1, \"mm\"), \r\n             column_title = NULL, row_title = NULL,\r\n             top_annotation = top_annos, left_annotation = left_annos,\r\n             # cell_fun = color_cell,\r\n             layer_fun = group_outline,\r\n             show_heatmap_legend = FALSE\r\n             )\r\n\r\n# save heatmap\r\npdf(file.path(dir1, \"Network Heatmap.pdf\"), width = 30, height = 30)\r\nprint(hm)\r\ndev.off()\r\n\r\n\r\n\r\nCalculate Centrality Scores\r\nCalculate the eigenvalue centrality scores for the entire graph. Then, remove isolated nodes for further visualization.\r\n\r\n\r\n# calculate centrality\r\ncent = eigen_centrality(net)$vector %>% data.table(Symbol = names(.), Centrality = .)\r\n\r\n# add to vertex data\r\ndat = dat %>% merge(cent, by = \"Symbol\") %>% .[order(-Centrality)]\r\nvertex_attr(net, \"Centrality\") = cent[, Centrality]\r\n\r\n# clean ID mapping\r\nids = ids[, .(queryItem, stringId, preferredName, annotation)]\r\nsetnames(ids, c(\"Symbol\", \"STRING.ID\", \"STRING.Symbol\", \"STRING.Annotation\"))\r\n\r\n# merge and save marker information\r\ndat %>% merge(ids, by = \"Symbol\", all.x = TRUE, sort = FALSE) %>%\r\n  fwrite(file.path(dir1, \"STRING ADRA Annotations.csv\"))\r\n\r\n# remove isolated vertices from network\r\nsub = delete_vertices(net, which(igraph::degree(net) <= 2))\r\npaste0(\"Proteins Retained in Network: \", length(V(sub)), \"/\", nrow(dat)) %>% message()\r\n\r\n\r\n\r\nPlot Circos Graph\r\nFirst, create a generic network plotting function which is called multiple times throughut the script.\r\n\r\n\r\nplot_network = function(net, layout, minmax, ..., arc = TRUE) {\r\n  \r\n  edge_geom = ifelse(arc, geom_edge_arc0, geom_edge_link0)\r\n  \r\n  p = ggraph(net, layout, ...) + \r\n    edge_geom(aes(width = escore), alpha = 0.4) +\r\n    scale_edge_width(range = c(0.2, 0.9)) +\r\n    geom_node_point(aes(color = Group, size = Centrality)) + scale_size(range = minmax) +\r\n    scale_color_manual(values = cols) +\r\n    theme_graph(fg_text_colour = \"black\", base_family = \"Helvetica\") + \r\n    guides(edge_width = FALSE, size = FALSE) +\r\n    labs(color = \"Group\")\r\n  \r\n  return(p)\r\n  \r\n}\r\n\r\n\r\n\r\nNext, create a function to plot a circos graph of the network, then plot the figure with and without labels. The labeling code is inspired by this tutorial from the R Graph Gallery. Spaces are used as an efficient trick to keep labels from overlapping with the nodes. Although the labels are truncated in the figure, they can be recovered with Inkscape (or an analogous vector editing tool).\r\n\r\n\r\nngrp = uniqueN(vertex_attr(sub, \"Group\"))\r\n\r\nplot_circos = function(net, minmax, fname, w, h, legend = FALSE) {\r\n  \r\n  p = plot_network(net, \"linear\", minmax, circular = TRUE, sort.by = Group)\r\n  \r\n  if(!legend) { p = p + theme(legend.position = \"none\") } else {\r\n    \r\n    p = p + # geom_node_label(aes(label = name), repel = TRUE, alpha = 0.8, segment.size = NA) +\r\n      geom_node_text(aes(label = Label, angle = Angle, hjust = Hjust)) +\r\n      theme(legend.title = element_text(face = \"bold\", size = 18, hjust = 0.5),\r\n            legend.text = element_text(size = 14), legend.position = \"bottom\",\r\n            plot.margin = unit(rep(-1, 4), \"cm\"))\r\n  }\r\n  \r\n  ggsave(file.path(dir1, fname), p, width = w, height = h)\r\n  \r\n}\r\n\r\n# generate angle for labels\r\nmd = sub %>%\r\n  { data.table(Name = vertex_attr(., \"name\"), Angle = length(V(.))) } %>%\r\n  .[, Angle := Angle %>% { (1:.[1] - 0.5)/. } %>% { 90 - (360*.) }] %>%\r\n  .[, Hjust := ifelse(Angle < -90, 1, 0)] %>%\r\n  .[, Label := ifelse(Angle < -90, paste0(Name, \"      \"), paste0(\"      \", Name))] %>%\r\n  .[, Angle := Angle %>% ifelse(. < -90, . + 180, .)]\r\n\r\n# assign to plot\r\nvertex_attr(sub, \"Angle\") = md$Angle\r\nvertex_attr(sub, \"Hjust\") = md$Hjust\r\nvertex_attr(sub, \"Label\") = md$Label\r\n\r\n\r\n# create and save plot\r\n# plot_circos(sub, c(2, 4), \"Circos Plot.pdf\", 8.5, 8.5)\r\nplot_circos(sub, c(2, 15), \"Circos Plot with Labels.pdf\", 18, 19, TRUE)\r\n\r\n\r\n\r\nPlot Chord Graph\r\nFirst, transform network to adjacency matrix, then group by function. We also define a utility merge function to retrieve the group for an arbitrary set of symbols - this will be useful later.\r\n\r\n\r\n# utility function to retrieve group\r\nget_grp = function(x, var) {\r\n  merge(x, dat[, .(Symbol, Group)], by.x = var, by.y = \"Symbol\", all.x = TRUE, sort = FALSE)\r\n}\r\n\r\n# melt to adjacency list\r\nadj = as.matrix(as_adj(sub)) %>% reshape2::melt() %>% setDT()\r\n\r\n# replace protein names with groups, then convert back to matrix\r\nadj = adj %>% .[value == 1, ] %>% get_grp(\"Var1\") %>% get_grp(\"Var2\") %>%\r\n  .[, .(Group.x, Group.y)] %>% graph_from_data_frame() %>% as_adj(sparse = FALSE)\r\n\r\n# reorder alphabetically to match colors\r\nadj = names(cols) %>% adj[., .]\r\n\r\n\r\n\r\nThe package circlize is used to create static chord diagrams, while the GitHub package mattflor/chorddiag is used to create interactive chord diagrams using the Javascript visualization library D3. Notice that, for the static plot, the alternating order defined previously (in alt) is used.\r\n\r\n\r\n# static plot\r\npdf(file.path(dir1, \"Chord Diagram.pdf\"), 12, 12)\r\n# circlize::chordDiagram(adj[alt, alt], transparency = 0.5, grid.col = cols[alt])\r\ncirclize::chordDiagram(adj, transparency = 0.5, grid.col = cols)\r\ndev.off()\r\n\r\n# interactive plot\r\nchorddiag(adj, groupColors = as.character(cols), groupnamePadding = 30, groupnameFontsize = \"10\") %>%\r\n  htmlwidgets::saveWidget(., file.path(dir1, \"Interactive Chord Diagram.html\"))\r\n\r\n\r\n\r\nPlot Network Graph\r\nCreate manual grouped layout to cluster by functional group (inspired by igraph::crossing() and this StackOverflow post).\r\n\r\n\r\n# check if two nodes are within the same cluster\r\nel = as_edgelist(sub) %>% as.data.table() %>% \r\n  get_grp(\"V1\") %>% get_grp(\"V2\") %>%\r\n  .[, Weights := ifelse(Group.x == Group.y, yes = 5, no = 25)]\r\n\r\n# # if nodes have no connections with their cluster, set weight as intermediate (to avoid clusters of n = 1)\r\n# for(v in V(sub)$name) {\r\n#   if(el[V1 == v | V2 == v, sum(Weights == 5) <= 1]) { el[V1 == v | V2 == v, Weights := 15] }\r\n# }\r\n\r\n# # create manual layout\r\nlyt = graphlayouts::layout_with_stress(sub, weights = el[, Weights]) %>%\r\n  as.data.table() %>% setnames(c(\"X\", \"Y\")) %>% .[, Symbol := vertex_attr(sub, \"name\")]\r\n\r\n# create manual layout\r\n# lyt = igraph::layout_with_kk(sub, weights = el[, Weights]) %>%\r\n#   as.data.table() %>% setnames(c(\"X\", \"Y\")) %>% .[, Symbol := vertex_attr(sub, \"name\")]\r\n\r\n\r\n\r\nThen, create network graph.\r\n\r\n\r\n# create network graph\r\nnetwork_graph = plot_network(sub, \"manual\", c(1, 10), x = lyt[, X], y = lyt[, Y], arc = FALSE) +\r\n  geom_node_label(aes(label = name), repel = TRUE, alpha = 0.8, \r\n                  box.padding = 0.5, segment.size = NA, label.size = 0.1, size = 8*(5/14)) +\r\n  theme(legend.title = element_text(size = 16, face = \"bold\"),\r\n        legend.text = element_text(size = 12.5), legend.position = \"bottom\")\r\n\r\n# save network graph\r\nggsave(file.path(dir1, \"Network Graph.pdf\"), network_graph, width = 15, height = 15)\r\n\r\n\r\n\r\nFinally, prune the network graph for the methods figure visualization.\r\n\r\n\r\n# prune network graph\r\nprune_graph = sub %>% delete_vertices(which(igraph::degree(.) <= 25))\r\nprune_lyt = lyt[Symbol %in% vertex_attr(prune_graph, \"name\")]\r\n  \r\n# create methods graph\r\nmethods_network = plot_network(prune_graph, \"manual\", c(5, 15), x = prune_lyt[, X], y = prune_lyt[, Y], arc = FALSE) + theme(legend.position = \"none\")\r\n\r\n# save methods graph\r\nggsave(file.path(dir1, \"Methods Graph.svg\"), methods_network, width = 10, height = 10)\r\n\r\n\r\n\r\nHub Gene Networks\r\nCreate networks for top hub markers emphasizing their connectivity. First, define a function\r\n\r\n\r\n# remove and recreate directory if it exists\r\nhub_dir = file.path(dir1, \"Hub Gene Networks\")\r\nif(fs::dir_exists(hub_dir)) fs::dir_delete(hub_dir); fs::dir_create(hub_dir)\r\n\r\nhub_network = function(hub, idx, PDF = TRUE, SVG = TRUE) {\r\n  \r\n  # duplicate network, identify hub node index\r\n  hub_net = copy(sub)\r\n  hub_idx = vertex_attr(hub_net, \"name\") == hub\r\n  \r\n  # label nodes by neighbor/hub status\r\n  # cat(paste0(\"[\", idx, \"] \", hub, \", \"))\r\n  vertex_attr(hub_net, \"hub_node\") = V(hub_net) %in% ego(hub_net, order = 1, nodes = hub)[[1]] %>%\r\n    as.numeric() %>% data.table(Label = .) %>%\r\n    .[hub_idx, Label := 2] %>%\r\n    .[, Label := factor(Label, levels = c(0, 1, 2), labels = c(\"node\", \"neighbor\", \"hub\"))] %>%\r\n    .[, as.character(Label)]\r\n  \r\n  # identify edges connected to the hub node\r\n  edge_attr(hub_net, \"hub_edge\") = as_edgelist(hub_net) %>% data.table() %>%\r\n    pmap_chr(paste) %>% grepl(hub, .)\r\n  \r\n  # create sub network for hub nodes and edges\r\n  sub_node_idx = which(vertex_attr(hub_net, \"hub_node\") %in% c(\"node\", \"hub\"))\r\n  sub_node_net = delete_vertices(hub_net, sub_node_idx)\r\n  sub_edge_net = delete_edges(hub_net, which(!edge_attr(hub_net, \"hub_edge\")))\r\n  \r\n  # plot hub network\r\n  hub_graph = ggraph(hub_net, \"manual\", x = lyt[, X], y = lyt[, Y]) +\r\n    geom_edge_link0(aes(width = hub_edge, color = hub_edge, alpha = hub_edge)) +\r\n    scale_edge_width_manual(values = c(0.2, 0.25)) +\r\n    scale_edge_color_manual(values = c(\"#3D405B\", \"#D3D3DA\")) +\r\n    scale_edge_alpha_manual(values = c(0.6, 0.4)) +\r\n    geom_node_point(aes(color = hub_node, size = hub_node)) + scale_size_manual(values = c(0, 2, 1)) +\r\n    scale_color_manual(values = c(\"#DB876B\", \"#FED766\", \"#3D405B\")) +\r\n    \r\n    # replot hub edges, then nodes, on top of previous graph (so they are non-overlapping)\r\n    geom_edge_link0(data = get_edges()(create_layout(sub_edge_net, layout = \"manual\", x = lyt[, X], y = lyt[, Y])),\r\n                    width = 0.25, color = \"#D3D3DA\", alpha = 0.6) +\r\n    geom_node_point(data= get_nodes()(create_layout(sub_node_net, layout = \"manual\",\r\n                                                    x = lyt[-sub_node_idx, X], y = lyt[-sub_node_idx, Y])),\r\n                    color = \"#FED766\", size = 2) +\r\n    \r\n    # plot hub node with label\r\n    ggforce::geom_circle(aes(x0 = lyt[hub_idx, X], y0 = lyt[hub_idx, Y], r = 5*(5/14)), fill = \"#DB876B\", color = NA) +\r\n    geom_text(aes(x = lyt[hub_idx, X], y = lyt[hub_idx, Y]),\r\n              label = hub, size = (3 + 4 * 1/nchar(hub))*(5/14), fontface = \"bold\", color = \"white\") +\r\n    theme_graph(fg_text_colour = \"white\", base_family = \"Helvetica\") +\r\n    theme(legend.position = \"none\")\r\n  \r\n  # save output\r\n  if(PDF) {ggsave(file.path(hub_dir, paste(idx, \"-\", hub, \"Network.pdf\")), hub_graph, width = 7, height = 7)}\r\n\r\n  if(SVG) {ggsave(file.path(hub_dir, paste0(idx, \"_\", hub, \"_Network.svg\")),\r\n                  hub_graph + theme(panel.background = element_rect(fill = \"#2B2F48\", color = \"#2B2F48\"),\r\n                                    plot.background = element_rect(fill = \"#2B2F48\", color = \"#2B2F48\")),\r\n                  width = 7, height = 7)}\r\n\r\n  return(hub_graph)\r\n  \r\n}\r\n\r\n# map function over all markers\r\nhub_graphs = imap(dat[Symbol %in% vertex_attr(sub, \"name\"), Symbol], ~hub_network(.x, .y, TRUE, TRUE))\r\ncat(\"DONE\")\r\n\r\n\r\n\r\nInteractive Network Graph\r\nCreate interactive network graph (with manual layout identical to above).\r\n\r\n\r\n# get network data\r\nnet_dat = get.data.frame(sub, \"both\")\r\n\r\n# parse nodes for interactive graph\r\nnodes = net_dat$vertices %>% as.data.table() %>%\r\n  setnames(c(\"name\", \"Centrality\"), c(\"id\", \"value\")) %>%\r\n  .[, label := id] %>%\r\n  .[, value := 60*(value+0.5)] %>%\r\n  .[, shape := \"circle\"] %>%\r\n  .[, color := factor(Group, levels = names(cols), labels = cols)] %>%\r\n  .[, .(id, label, value, shape, color)]\r\n\r\n# parse edges for interactive graph\r\nedges = net_dat$edges %>% as.data.table() %>%\r\n  setnames(\"escore\", \"value\") %>%\r\n  .[, value := value + 0.1] %>%\r\n  .[, color := \"rgba(0,0,0,0.5)\"] %>%\r\n  .[, title := paste(from, to, sep = \" to \")] %>%\r\n  .[, .(from, to, value, color, title)]\r\n\r\n# create interactive network graph\r\nint_net = visNetwork(nodes, edges) %>%\r\n  visOptions(height = 800, width = 1200,\r\n             highlightNearest = TRUE, clickToUse = TRUE,\r\n             nodesIdSelection = list(main = \"Select Gene\")) %>%\r\n  visInteraction(navigationButtons = TRUE, dragView = FALSE) %>%\r\n  visIgraphLayout(\"layout_with_kk\",\r\n                  coords = as.matrix(lyt[, .(X, Y)]), maxiter = 0)\r\n\r\nvisSave(int_net, file.path(dir1, \"Interactive Network Graph.html\"))\r\n\r\n\r\n\r\n\r\n\r\n\r\n[1] Szklarczyk D, Gable AL, Lyon D, Junge A, Wyder S, Huerta-Cepas J, et al. STRING v11: Protein-protein association networks with increased coverage, supporting functional discovery in genome-wide experimental datasets. Nucleic Acids Research 2019;47:D607â€“13. https://doi.org/10.1093/nar/gky1131.\r\n\r\n\r\n[2] The UniProt Consortium. UniProt: The universal protein knowledgebase in 2021. Nucleic Acids Research 2021;49:D480â€“9. https://doi.org/10.1093/nar/gkaa1100.\r\n\r\n\r\n[3] Tweedie S, Braschi B, Gray K, Jones TEM, Seal RL, Yates B, et al. Genenames.org: The HGNC and VGNC resources in 2021. Nucleic Acids Research 2021;49:D939â€“46. https://doi.org/10.1093/nar/gkaa980.\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2021-07-16T11:49:36-07:00"
    },
    {
      "path": "omics-comparison.html",
      "title": "-Omics Comparison",
      "description": "This script compares the ADRA protein set with recent transcriptomic and proteomic studies on human control and AD brains.\n",
      "author": [
        {
          "name": {},
          "url": "https://www.github.com/ayushnoori"
        }
      ],
      "contents": "\r\n\r\nContents\r\nDependencies\r\nGeneric Functions\r\nSimpson et al.\r\nRead Simpson et al.Â Data\r\nDifferential Expression Analysis\r\nPrepare for Heatmap\r\nPlot Heatmap\r\n\r\nGrubman et al.\r\nRead Grubman et al.Â Data\r\nPlot Heatmap\r\n\r\nJohnson et al.\r\nRead Bulk Brain Data\r\nPlot Bulk Brain Heatmap\r\nRead CSF Data\r\nPlot CSF Heatmap\r\nPlot Specific Marker\r\n\r\nHypergeometric Enrichment Tests\r\n\r\nDependencies\r\nLoad requisite packages. This script requires version 2.2.14 of the ff package, which may be installed by devtools::install_version(\"ff\", version = \"2.2.14\", repos = \"http://cran.us.r-project.org\"). The microarray annotation packages are available from R/Bioconductor.\r\nThis script also uses my personal utilities package brainstorm, which can be downloaded via devtools::install_github(\"ayushnoori/brainstorm\")\r\n\r\n\r\n# data manipulation\r\nlibrary(data.table)\r\nlibrary(purrr)\r\nlibrary(magrittr)\r\n\r\n# heatmap libraries\r\nlibrary(ggplot2)\r\nlibrary(RColorBrewer)\r\nlibrary(pheatmap)\r\n\r\n# Excel manipulation\r\nlibrary(openxlsx)\r\n\r\n# Simpson et al. microarray analysis\r\nlibrary(GEOquery)\r\nlibrary(ff)\r\nlibrary(affycoretools)\r\nlibrary(oligo)\r\nlibrary(limma)\r\n\r\n# Simpson et al. microarray annotation\r\nlibrary(pd.hg.u133.plus.2)\r\nlibrary(hgu133plus2.db)\r\n\r\n# utility functions\r\nlibrary(brainstorm)\r\n\r\n\r\n\r\nNote that directories are relative to the R project path.\r\n\r\n\r\n# set directories\r\nddir = file.path(\"Data\", \"4 - Cross-Validation\")\r\ndir4 = file.path(\"Results\", \"4 - Cross-Validation\")\r\n\r\n\r\n\r\nGeneric Functions\r\nRead ADRA protein set.\r\n\r\n\r\n# read data\r\ndat = fread(file.path(\"Data\", \"ADRA Protein Set.csv\"), encoding = \"UTF-8\")\r\n\r\n\r\n\r\nDefine generic z-score function.\r\n\r\n\r\n# define z-score function\r\ncompute_z = function(x) { (x - mean(x, na.rm = T))/sd(x, na.rm = T) }\r\n\r\n\r\n\r\nCreate generic heatmap plotting function. Here, bounds is a vector of length 2 which specifies the lower and upper bounds, respectively.\r\n\r\n\r\nplot_heatmap = function(hm_dat, hm_ann_row = NA, hm_ann_col = NA, hm_colors,\r\n                        hm_gaps_row = NULL, hm_gaps_col = NULL, bounds) {\r\n  \r\n  p = pheatmap(hm_dat, \r\n               color = colorRampPalette(rev(brewer.pal(n = 11, name = \"RdYlBu\")))(100),\r\n               breaks = seq(from = bounds[1], to = bounds[2], length.out = 101),\r\n               cluster_cols = FALSE, cluster_rows = FALSE,\r\n               annotation_row = hm_ann_row,\r\n               annotation_col = hm_ann_col,\r\n               annotation_names_row = FALSE,\r\n               annotation_colors = hm_colors,\r\n               border_color = NA,\r\n               show_colnames = FALSE,\r\n               gaps_row = hm_gaps_row,\r\n               gaps_col = hm_gaps_col,\r\n               silent = TRUE)\r\n}\r\n\r\nplot_n = function(n, hm_dat, ...) {\r\n  \r\n  hm_dat = rbind(head(hm_dat, n), tail(hm_dat, n))\r\n  \r\n  hm_ann_row = data.frame(Direction = rep(c(\"Upregulated\", \"Downregulated\"), each = n))\r\n  rownames(hm_ann_row) = rownames(hm_dat)\r\n  \r\n  plot_heatmap(hm_dat = hm_dat, hm_ann_row = hm_ann_row, hm_gaps_row = c(n), ...) %>% return()\r\n  \r\n}\r\n\r\n\r\n\r\nSimpson et al.\r\nRead, parse, analyze, and plot data from Simpson et al., a microarray expression profiling dataset of laser capture microdissected GFAP-immunoreactive astrocytes from the temporal neocortex of n = 6 Braak I/II, n = 6 Braak III/IV, and n = 6 Braak V/VI subjects [1].\r\nGene Expression Omnibus (GEO) Accession: GSE29652\r\nRead Simpson et al.Â Data\r\nFirst, import .CEL files containing raw probe-level data into an R AffyBatch object. Next, perform RMA data processing and convert to an ExpressionSet. Then, annotate using the Affymetrix hgu133plus2.db package. Probes with duplicate mappings are removed by retaining the probe with the highest interquartile range (IQR).\r\n\r\n\r\n# read and normalize .CEL files\r\ngset = list.files(path = file.path(ddir, \"Simpson\"), pattern = \"\\\\.CEL$\", full.names = TRUE) %>% \r\n  read.celfiles() %>% \r\n  oligo::rma() %>% # default level of summarization\r\n  annotateEset(hgu133plus2.db)\r\n\r\n# get expression data and annotation\r\nsimpson = exprs(gset) %>% as.ffdf() %>% \r\n  as.data.table(keep.rownames = TRUE) %>%\r\n  merge(fData(gset), ., by.x = \"PROBEID\", by.y = \"rn\", all.y = TRUE)\r\n\r\n# get sample column names\r\nsimpson_samples = colnames(simpson) %>% .[!(. %in% fvarLabels(gset))]\r\n\r\n# calculate IQR, then remove probes with duplicate mappings\r\nsimpson = as.data.table(simpson) %>%\r\n  .[, IQR := pmap_dbl(.SD, ~IQR(.(...), na.rm = TRUE)), .SDcols = simpson_samples] %>%\r\n  .[order(ENTREZID, IQR), ] %>%\r\n  .[!duplicated(ENTREZID), ]\r\n\r\n\r\n\r\nDifferential Expression Analysis\r\nPerform differential expression analysis on Simpson et al.Â data. Compare Braak I/II and Braak V/VI subjects.\r\n\r\n\r\n# select samples\r\ngset = gset[simpson$PROBEID, c(1:6, 13:18)]\r\nsml = c(rep(\"G0\", 6), rep(\"G1\", 6))\r\n\r\n# set up the data and proceed with analysis\r\nfl = as.factor(sml)\r\ngset$description = fl\r\ndesign = model.matrix(~ description + 0, gset)\r\ncolnames(design) = levels(fl)\r\n\r\n# linear model fit\r\nfit = lmFit(gset, design)\r\ncont.matrix = makeContrasts(G1-G0, levels = design)\r\nfit2 = contrasts.fit(fit, cont.matrix)\r\nfit2 = eBayes(fit2, 0.01)\r\ntT = topTable(fit2, adjust = \"fdr\", sort.by = \"B\", number = nrow(gset), confint = TRUE) %>% as.data.table()\r\n\r\n# append expression matrix to results, then write to Excel file\r\nsimpson_degs = exprs(gset) %>%\r\n  as.data.table(keep.rownames = TRUE) %>%\r\n  merge(tT, ., by.x = \"PROBEID\", by.y = \"rn\", all.x = TRUE, all.y = FALSE)\r\n\r\nwrite.xlsx(simpson_degs, file.path(dir4, \"Simpson - Differential Expression Analysis.xlsx\"), \r\n           asTable = TRUE, tableStyle = \"TableStyleMedium5\")\r\n\r\n\r\n\r\nPrepare for Heatmap\r\nMerge Simpson et al.Â data with ADRA marker set and compute z-scores.\r\n\r\n\r\n# subset markers in intersection of ADRA and Simpson et al.\r\nsimpson_z = simpson[SYMBOL %in% dat[, Symbol], ]\r\n\r\n# remove .CEL file extension\r\nsimpson_samples %>% setnames(simpson_z, ., gsub(\".CEL\", \"\", .))\r\nsimpson_samples = gsub(\".CEL\", \"\", simpson_samples)\r\n\r\n# compute z-scores within each marker\r\nsimpson_z[, (simpson_samples) := pmap_dfr(.SD, ~compute_z(c(...))), .SDcols = simpson_samples]\r\n\r\n# create heatmap object\r\nsimpson_hm = simpson_z[, ..simpson_samples] %>% as.matrix()\r\nrownames(simpson_hm) = simpson_z[, SYMBOL]\r\n\r\n# order rows by difference between control and AD\r\nsimpson_hm = simpson_hm %>%\r\n  { rowMeans(.[, 13:18]) - rowMeans(.[, 1:6]) } %>%\r\n  order(decreasing = TRUE) %>%\r\n  simpson_hm[., ]\r\n\r\n\r\n\r\nRead Simpson et al.Â metadata and create both annotation data.frame and color palette.\r\n\r\n\r\n# read metadata to create heatmap annotations\r\nsimpson_hm_col = file.path(ddir, \"Simpson\", \"GSE29652_series_matrix.txt.gz\") %>%\r\n  getGEO(filename = ., getGPL = FALSE) %>% pData() %>%\r\n  .[simpson_samples, ] %>% subset(select = \"braak stage:ch1\")\r\n\r\n# set column names\r\ncolnames(simpson_hm_col) = \"Braak Stage\"\r\n\r\n# define heatmap colors\r\nsimpson_hm_colors = list(`Braak Stage` = c(`Braak I-II` = \"#0EAD69\", `Braak III-IV` = \"#EFCB68\", `Braak V-VI` = \"#D7263D\"),\r\n                Direction = c(Upregulated = \"#A50026\", Downregulated = \"#3D5CA7\"))\r\n\r\n# order columns\r\nsimpson_hm = simpson_hm_col %>% \r\n  order(.$`Braak Stage`, colMeans(simpson_hm)) %>%\r\n  simpson_hm[, .]\r\n\r\n\r\n\r\nPlot Heatmap\r\n\r\n\r\n# plot full heatmap\r\nsimpson_hm_full = plot_heatmap(hm_dat = simpson_hm, hm_ann_col = simpson_hm_col, hm_colors = simpson_hm_colors,\r\n                       hm_gaps_col = c(6, 12), bounds = c(-2.5, 2.5))\r\n\r\n# save full heatmap\r\nggsave(file.path(dir4, \"Simpson - Full Heatmap.pdf\"), simpson_hm_full, width = 10, height = 30)\r\n\r\n\r\n# plot heatmap with top N UP/DOWN genes\r\nfor (i in c(15, 30)) {\r\n  \r\n  simpson_hm_n = plot_n(n = i, hm_dat = simpson_hm, hm_ann_col = simpson_hm_col, hm_colors = simpson_hm_colors,\r\n                       hm_gaps_col = c(6, 12), bounds = c(-2.5, 2.5))\r\n\r\n  ggsave(file.path(dir4, paste(\"Simpson - Top\", i*2, \"Heatmap.pdf\")), simpson_hm_n, width = 10, height = i/3.5 + 2)\r\n  \r\n}\r\n\r\n\r\n\r\nGrubman et al.\r\nRead, parse, analyze, and plot data from Grubman et al., a single nuclei RNA-seq study on the entorhinal cortex of n = 6 AD and n = 6 control subjects. Here, the data file contains single-cell log-normalized counts [2].\r\nRead Grubman et al.Â Data\r\nRead Grubman et al.Â data.\r\n\r\n\r\n# set metadata columns\r\ngrubman_md = c(\"sampleID\", \"batch\", \"patient\", \"batchCond\", \"sex\", \"nGene\")\r\n\r\n# read grubman annotations, select astrocytes, and remove unidentified cells\r\ngrubman_annot = fread(file.path(ddir, \"Grubman\", \"Grubman Annotations.tsv\")) %>%\r\n  .[cellType == \"astro\", ] %>%\r\n  .[!(patient %in% c(\"AD-un\", \"Ct-un\")), ] %>%\r\n  .[order(patient), ..grubman_md]\r\n\r\n# read grubman data\r\ngrubman = fread(file.path(ddir, \"Grubman\", \"Grubman Data.tsv\")) %>%\r\n  .[geneName %in% dat[, Symbol], ] %>%\r\n  data.table::transpose(keep.names = \"sampleID\", make.names = \"geneName\") %>%\r\n  merge(grubman_annot, ., by = \"sampleID\", all.x = TRUE, sort = FALSE)\r\n\r\n# get marker names\r\ngrubman_adra = colnames(grubman) %>% .[!(. %in% grubman_md)]\r\n\r\n\r\n\r\nCompute z-scores within each marker, then average z-score across each patient.\r\n\r\n\r\n# compute z-scores within each marker\r\ngrubman[, (grubman_adra) := map(.SD, compute_z), .SDcols = grubman_adra]\r\n\r\n# compute average z-scores across each patient\r\ngrubman_z = grubman[, map(.SD, ~mean(..., na.rm = TRUE)), by = .(patient, batchCond), .SDcols = grubman_adra] %>%\r\n  .[, Condition := factor(batchCond, levels = c(\"ct\", \"AD\"), labels = c(\"Control\", \"Alzheimer\"))] %>%\r\n  .[order(Condition, patient), ]\r\n\r\n# order columns by difference between control and AD\r\ngrubman_colorder = grubman_z[, map(.SD, mean), by = Condition, .SDcols = grubman_adra] %>%\r\n  .[, ..grubman_adra] %>% {.[2, ] - .[1, ]} %>% setcolorder(order(-.)) %>% names()\r\n\r\n# prepare for heatmap\r\ngrubman_hm = t(grubman_z)[grubman_colorder, ]\r\nclass(grubman_hm) = \"numeric\"\r\ncolnames(grubman_hm) = grubman_z[, patient]\r\n\r\n# create heatmap annotation\r\ngrubman_hm_col = grubman_z[, .(Condition)] %>% as.data.frame()\r\nrownames(grubman_hm_col) = grubman_z[, patient]\r\n\r\n# order columns\r\ngrubman_hm = grubman_hm_col %>% \r\n  order(.$Condition, -colMeans(grubman_hm), decreasing = TRUE) %>%\r\n  grubman_hm[, .]\r\n\r\n# create heatmap color palette\r\ngrubman_hm_colors = list(Condition = c(Control = \"#0EAD69\", Alzheimer = \"#D7263D\"),\r\n                       Direction = c(Upregulated = \"#A50026\", Downregulated = \"#3D5CA7\"))\r\n\r\n\r\n\r\nPlot Heatmap\r\nCreate the heatmap for the Grubman et al.Â data. To calculate quantiles, run quantile(grubman_hm, c(0.01, 0.99).\r\n\r\n\r\n# plot full heatmap\r\ngrubman_hm_full = plot_heatmap(hm_dat = grubman_hm, hm_ann_col = grubman_hm_col, hm_colors = grubman_hm_colors,\r\n                       hm_gaps_col = c(6), bounds = c(-0.6, 0.6))\r\n\r\n# save full heatmap\r\nggsave(file.path(dir4, \"Grubman - Full Heatmap.pdf\"), grubman_hm_full, width = 8, height = 17)\r\n\r\n\r\n# plot heatmap with top N UP/DOWN genes\r\nfor (i in c(15, 30)) {\r\n  \r\n  grubman_hm_n = plot_n(n = i, hm_dat = grubman_hm, hm_ann_col = grubman_hm_col, hm_colors = grubman_hm_colors,\r\n                       hm_gaps_col = c(6), bounds = c(-0.6, 0.6))\r\n\r\n  ggsave(file.path(dir4, paste(\"Grubman - Top\", i*2, \"Heatmap.pdf\")), grubman_hm_n, width = 10, height = i/3.5 + 2)\r\n  \r\n}\r\n\r\n\r\n\r\nJohnson et al.\r\nRead, parse, analyze, and plot data from Johnson et al.Â from the Accelerating Medicines Partnership-Alzheimerâ€™s Disease (AMP-AD) Consortium [3]. Our analysis of Johnson et al.Â encompasses:\r\nA bulk brain proteomic dataset on the dorsolateral prefrontal cortex (BA9) of 419 individuals from four cohorts, encompassing n = 91 control (Braak 0-III and cognitively normal), n = 98 asymptomatic AD (Break III-VI, but cognitively normal), and n = 230 AD dementia subjects (Braak IV-VI and cognitively impaired), with 3,334 proteins identified in > 50% subjects.\r\nCohort 1 of the CSF proteomic study, which includes n = 147 control and n = 150 AD subjects (total n = 297 subjects).\r\nRead Bulk Brain Data\r\nRead and analyze bulk brain proteomics data from the Johnson et al.Â AMP-AD dataset.\r\n\r\n\r\n# read johnson bulk data\r\nbulk = fread(file.path(ddir, \"Johnson\", \"Bulk Brain\", \"Johnson Bulk Data.csv\"), check.names = TRUE) %>%\r\n  .[, Marker := map_chr(strsplit(orange..does.not.follow.rules.to.left, \"|\", fixed = TRUE), 1)]\r\n\r\n# get sample names\r\nbulk_samples = colnames(bulk)[23:441]\r\n\r\n# select markers in ADRA set then compute z-scores within each marker\r\nbulk = c(\"Marker\", bulk_samples) %>%\r\n  bulk[Marker %in% dat$Symbol, .SD, .SDcols = .] %>%\r\n  .[, (bulk_samples) := pmap_dfr(.SD, ~compute_z(c(...))), .SDcols = bulk_samples]\r\n\r\n\r\n\r\nRead annotation data. Remove duplicates and proteins with > 50% missing values, then merge with annotations.\r\n\r\n\r\n# read johnson bulk annotations\r\nbulk_annot = fread(file.path(ddir, \"Johnson\", \"Bulk Brain\", \"Johnson Bulk Annotations.csv\"), check.names = TRUE) %>%\r\n  .[Group %in% c(\"Control\", \"AsymAD\", \"AD\"), .(RAW.File.Name, Sex..male.1., Age, PMI, CERAD, Braak, Group)]\r\nsetnames(bulk_annot, c(\"RAW.File.Name\", \"Sex..male.1.\"), c(\"Sample\", \"Sex\"))\r\n\r\n# filter, then merge\r\nbulk = bulk %>%\r\n  .[!duplicated(Marker), ] %>%\r\n  .[, MissingCount := pmap_int(.SD, ~sum(is.na(c(...)))), .SDcols = bulk_samples] %>%\r\n  .[MissingCount < length(bulk_samples)/2, ] %>% .[, MissingCount := NULL] %>%\r\n  data.table::transpose(keep.names = \"Sample\", make.names = \"Marker\") %>%\r\n  merge(bulk_annot, ., by = \"Sample\", all.x = FALSE, all.y = TRUE) %>%\r\n  .[, Condition := factor(Group, levels = c(\"Control\", \"AsymAD\", \"AD\"), labels = c(\"Control\", \"AsymAD\", \"Alzheimer\"))] %>%\r\n  .[, Braak := factor(Braak, levels = 0:6, labels = c(\"Braak 0\", \"Braak I\", \"Braak II\", \"Braak III\", \"Braak IV\",\r\n                                                      \"Braak V\", \"Braak VI\"))] %>%\r\n  .[order(Condition, Braak), ]\r\n\r\n\r\n\r\nAverage z-score across Braak stage within each diagnostic group.\r\n\r\n\r\n# get marker names\r\nbulk_adra = colnames(bulk) %>% .[!(. %in% c(colnames(bulk_annot), \"Condition\"))]\r\n\r\n# compute average z-scores across Braak stage\r\nbulk_z = bulk[, map(.SD, ~mean(..., na.rm = TRUE)), by = .(Condition, Braak), .SDcols = bulk_adra] %>%\r\n  .[, GroupNames := make.names(paste(Condition, Braak))]\r\n\r\n# order columns by difference between control and AD\r\nbulk_colorder = bulk_z[, map(.SD, mean), by = Condition, .SDcols = bulk_adra] %>%\r\n  .[, ..bulk_adra] %>% {.[3, ] - .[1, ]} %>% setcolorder(order(-.)) %>% names()\r\n\r\n# prepare for heatmap\r\nbulk_hm = t(bulk_z)[bulk_colorder, ]\r\nclass(bulk_hm) = \"numeric\"\r\ncolnames(bulk_hm) = bulk_z[, GroupNames]\r\n\r\n# create heatmap annotation\r\nbulk_hm_col = bulk_z[, .(Braak, Condition)] %>% as.data.frame()\r\ncolnames(bulk_hm_col)[1] = \"Braak Stage\"; rownames(bulk_hm_col) = bulk_z[, GroupNames]\r\n\r\n# create heatmap color palette\r\nbulk_hm_colors = list(\r\n  Condition = c(Control = \"#0EAD69\", AsymAD = \"#EFCB68\", Alzheimer = \"#D7263D\"),\r\n  `Braak Stage` = c(`Braak 0`=\"#0EAD69\", `Braak I`=\"#59B768\", `Braak II`=\"#A3C168\",\r\n            `Braak III`=\"#EFCB68\", `Braak IV`=\"#E79459\", `Braak V`=\"#DF5D4B\", `Braak VI`=\"#D7263D\"),\r\n  Direction = c(Upregulated = \"#A50026\", Downregulated = \"#3D5CA7\")\r\n)\r\n\r\n\r\n\r\nPlot Bulk Brain Heatmap\r\nCreate the heatmap for the Johnson et al.Â bulk brain data.\r\n\r\n\r\n# plot full heatmap\r\nbulk_hm_full = plot_heatmap(hm_dat = bulk_hm, hm_ann_col = bulk_hm_col, hm_colors = bulk_hm_colors,\r\n                       hm_gaps_col = c(4, 8), bounds = c(-0.6, 0.6))\r\n\r\n# save full heatmap\r\nggsave(file.path(dir4, \"Johnson Bulk Brain - Full Heatmap.pdf\"), bulk_hm_full, width = 10, height = 12)\r\n\r\n\r\n# plot heatmap with top N UP/DOWN genes\r\nfor (i in c(15, 30)) {\r\n  \r\n  bulk_hm_n = plot_n(n = i, hm_dat = bulk_hm, hm_ann_col = bulk_hm_col, hm_colors = bulk_hm_colors,\r\n                       hm_gaps_col = c(4, 8), bounds = c(-0.6, 0.6))\r\n\r\n  ggsave(file.path(dir4, paste(\"Johnson Bulk Brain - Top\", i*2, \"Heatmap.pdf\")), bulk_hm_n, width = 10, height = i/3.5 + 2)\r\n  \r\n}\r\n\r\n\r\n\r\nRead CSF Data\r\nRead and analyze Cohort 1 CSF proteomics data from the Johnson et al.Â AMP-AD dataset.\r\n\r\n\r\n# read and clean johnson CSF data\r\ncsf = fread(file.path(ddir, \"Johnson\", \"CSF\", \"Cohort 1 Clean Data.csv\"), check.names = TRUE) %>%\r\n  .[, Marker := map_chr(strsplit(V1, \"|\", fixed = TRUE), 1)] %>%\r\n  .[!duplicated(Marker), ] %>%\r\n  .[!Marker == \"0\", ]\r\n\r\n# get sample names\r\ncsf_samples = colnames(csf) %>% .[!(. %in% c(\"V1\", \"Marker\"))]\r\n\r\n# select markers in ADRA set then compute z-scores across markers\r\ncsf = c(\"Marker\", csf_samples) %>%\r\n  csf[Marker %in% dat$Symbol, .SD, .SDcols = .] %>%\r\n  .[, (csf_samples) := pmap_dfr(.SD, ~compute_z(c(...))), .SDcols = csf_samples]\r\n\r\n\r\n\r\nRead annotation data. Remove duplicates and proteins with > 33% missing values, then merge with annotations.\r\n\r\n\r\n# read johnson CSF annotations\r\ncsf_annot = fread(file.path(ddir, \"Johnson\", \"CSF\", \"Cohort 1 Traits.csv\"), check.names = TRUE) %>%\r\n  .[Group %in% c(\"Control\", \"AD\"), .(SampleID, Batch, Group, Age, Sex, Race, MoCA,\r\n                                     APOE.Genotype, AB42.ELISA, tTau.ELISA, pTau.ELISA)] %>%\r\n  .[, Ratio := AB42.ELISA/pTau.ELISA] %>%\r\n  .[, Percentile := cut(Ratio, quantile(Ratio, probs = seq(0, 1, 0.1), na.rm = TRUE),\r\n                      labels = FALSE, include.lowest = TRUE)] %>%\r\n  .[order(Percentile), ] %>%\r\n  .[, Percentile := factor(Percentile, levels = 1:10, labels = c(\"0-10%\", \"10-20%\", \"20-30%\", \"30-40%\", \"40-50%\", \"50-60%\", \r\n                                                             \"60-70%\", \"70-80%\", \"80-90%\", \"90-100%\"))]\r\n\r\n# correct sample name\r\nsetnames(csf_annot, \"SampleID\", \"Sample\")\r\n\r\n# filter, then merge\r\ncsf = csf %>%\r\n  .[, MissingCount := pmap_int(.SD, ~sum(is.na(c(...)))), .SDcols = csf_samples] %>%\r\n  .[MissingCount < length(csf_samples)/3, ] %>% .[, MissingCount := NULL] %>%\r\n  data.table::transpose(keep.names = \"Sample\", make.names = \"Marker\") %>%\r\n  merge(csf_annot, ., by = \"Sample\", all.x = FALSE, all.y = TRUE) %>%\r\n  .[!is.na(Percentile), ] %>%\r\n  .[order(Percentile, Ratio, decreasing = TRUE), ]\r\n\r\n\r\n\r\nAverage z-score across deciles of A\\(\\beta_{42}\\)/p-Tau ratio, which is a proxy for the severity of AD neuropathological changes.\r\n\r\n\r\n# get marker names\r\ncsf_adra = colnames(csf) %>% .[!(. %in% colnames(csf_annot))]\r\n\r\n# compute average z-scores across Braak stage\r\ncsf_z = csf[, map(.SD, ~mean(..., na.rm = TRUE)), by = .(Percentile), .SDcols = csf_adra]\r\n\r\n# order columns by difference between control and AD\r\ncsf_colorder = copy(csf_z) %>% .[, Group := c(rep(\"low\", 4), rep(\"medium\", 2), rep(\"high\", 4))] %>%\r\n  .[, map(.SD, mean), by = Group, .SDcols = csf_adra] %>%\r\n  .[, ..csf_adra] %>% {.[3, ] - .[1, ]} %>% setcolorder(order(-.)) %>% names()\r\n\r\n# prepare for heatmap\r\ncsf_hm = t(csf_z)[csf_colorder, ]\r\nclass(csf_hm) = \"numeric\"\r\ncolnames(csf_hm) = csf_z[, Percentile]\r\n\r\n# create heatmap annotation\r\ncsf_hm_col = csf_z[, .(Percentile)] %>% as.data.frame()\r\nrownames(csf_hm_col) = csf_z[, Percentile]\r\n\r\n# create heatmap color palette\r\ncsf_hm_colors = list(\r\n  Percentile = colorRampPalette(c(\"#0EAD69\", \"#F4E515\", \"#D7263D\"))(10) %>% set_names(unique(csf_z[, Percentile]))\r\n)\r\n\r\n\r\n\r\nPlot CSF Heatmap\r\nCreate the heatmap for the Johnson et al.Â CSF data.\r\n\r\n\r\n# plot full heatmap\r\ncsf_hm_full = plot_heatmap(hm_dat = csf_hm, hm_ann_col = csf_hm_col, hm_colors = csf_hm_colors, bounds = c(-0.8, 0.8))\r\n\r\n# save full heatmap\r\nggsave(file.path(dir4, \"Johnson CSF - Full Heatmap.pdf\"), csf_hm_full, width = 7, height = 7)\r\n\r\n\r\n\r\nPlot Specific Marker\r\nGeneric function for creating barplots for specific markers from Johnson et al.Â CSF data.\r\n\r\n\r\nplot_marker = function(mx, idx) {\r\n  \r\n    p = ggplot(csf_z, aes(x = Percentile, y = get(mx), fill = get(mx))) +\r\n    geom_col() +\r\n    scale_fill_gradient2(low = \"#5083BB\", mid = \"#D8DDDE\", high = \"#DE3F2E\", midpoint = 0) +\r\n    ggtitle(mx) + xlab(\"Percentile\") +\r\n    ylab(\"Z-Score\") +\r\n    theme_light() +\r\n    theme(plot.title = element_text(face = \"bold\", color = \"#30343F\", size = 20, hjust = 0.5),\r\n          axis.title.x = element_text(face = \"bold\", size = 12, color = \"#30343F\"),\r\n          axis.title.y = element_text(face = \"bold\", size = 12, color = \"#30343F\"),\r\n          strip.text.x = element_text(size = 12, face = \"bold\"),\r\n          legend.position = \"none\")\r\n\r\n  ggsave(file.path(dir4, \"Johnson CSF - Marker Plots\", paste(idx, \"-\", mx, \"Barplot.pdf\")), p, width = 7, height = 7)\r\n\r\n}\r\n\r\n\r\n\r\nSelect and plot specific markers.\r\n\r\n\r\n# remove and recreate directory if it exists\r\nfile.path(dir4, \"Johnson CSF - Marker Plots\") %>% { if(dir.exists(.)) { unlink(., recursive=TRUE); dir.create(.)} \r\n  else dir.create(.) }\r\n\r\n# select markers\r\nmxlist = csf_hm %>% { rbind(head(., 5), tail(., 5)) } %>% rownames()\r\n\r\n# plot markers\r\nmxplots = iwalk(mxlist, plot_marker)\r\n\r\n\r\n\r\nHypergeometric Enrichment Tests\r\nPerform hypergeometric enrichment tests. First, define a generic hypergeometric enrichment function.\r\n\r\n\r\nhyper_test = function(geneSet1, geneSet2, label) {\r\n  \r\n  # checking for enrichment of geneSet1 in geneSet2\r\n  success = intersect(geneSet1, geneSet2)\r\n  q = length(success) # number of successes (i.e., intersection of 196 ADRA markers with DEGs)\r\n  \r\n  s = length(geneSet1) # sample size (i.e., 196 proteins)\r\n  m = length(geneSet2) # module size (i.e., number of DEGs)\r\n  n = 21306 # population size, number of genes in the universe\r\n  # see https://www.biorxiv.org/content/10.1101/332825v2\r\n  \r\n  cat(paste0(label, \":\\n\"))\r\n  cat(paste0(\"Overlap Ratio: \", q, \"/\", s, \" = \", round(q/s*100, 4), \"%\", \"\\n\"))\r\n  cat(paste0(\"Gene Set Size: \", m, \"\\n\"))\r\n  \r\n  p = phyper(q, m, n, s, lower.tail = F)\r\n  cat(paste0(\"p-value: \", p, \"\\n\\n\"))\r\n  \r\n  return(p)\r\n  \r\n}\r\n\r\n\r\n\r\nDefine gene lists for hypergeometric enrichment tests. For the Johnson et al.Â bulk brain proteomics data, the column Control-AD is the Tukey p-value, while the column diff.Control-AD is average log2(Control) minus average log2(AD).\r\n\r\n\r\n# define directory\r\nhdir = file.path(ddir, \"Hypergeometric Enrichment Tests\")\r\n\r\n# read johnson bulk brain at p < 0.05\r\nbulk_0.05 = fread(file.path(hdir, \"Johnson DEGs.csv\")) %>%\r\n  .[(`with.<50%.missing?`), ] %>%\r\n  .[`Control-AD`< 0.05, geneName]\r\n\r\n# read grubman genes at p < 0.05 and LFC > 0.5\r\ngrubman_0.05_0.5 = fread(file.path(hdir, \"Grubman DEGs LFC-0.5 FDR-0.05.csv\"))[, geneName]\r\n\r\n# retrieve simpson genes from prior chunk\r\nsimpson_0.05 = simpson_degs[P.Value < 0.05, SYMBOL]\r\n\r\n# aggregate gene lists\r\ngene_lists = list(bulk_0.05, grubman_0.05_0.5, simpson_0.05)\r\nnames(gene_lists) = c(\"Johnson et al. p-value < 0.05\", \"Grubman et al. FDR < 0.05 and LFC > 0.5\", \r\n                      \"Simpson et al. p-value < 0.05\")\r\n\r\n\r\n\r\nPerform hypergeometric enrichment tests.\r\n\r\n\r\n# perform test\r\nhyper_results = imap(gene_lists, ~hyper_test(dat[, Symbol], .x, .y))\r\n\r\n# pipe results to output\r\nsink(file.path(dir4, \"Hypergeometric Enrichment Test Results.txt\"), append = FALSE)\r\nhyper_results = imap(gene_lists, ~hyper_test(dat[, Symbol], .x, .y))\r\nsink()\r\n\r\n\r\n\r\n\r\n\r\n\r\n[1] Simpson JE, Ince PG, Shaw PJ, Heath PR, Raman R, Garwood CJ, et al. Microarray analysis of the astrocyte transcriptome in the aging brain: Relationship to Alzheimerâ€™s pathology and APOE genotype. Neurobiology of Aging 2011;32:1795â€“807. https://doi.org/10.1016/j.neurobiolaging.2011.04.013.\r\n\r\n\r\n[2] Grubman A, Chew G, Ouyang JF, Sun G, Choo XY, McLean C, et al. A single-cell atlas of entorhinal cortex from individuals with Alzheimerâ€™s disease reveals cell-type-specific gene expression regulation. Nature Neuroscience 2019;22:2087â€“97. https://doi.org/10.1038/s41593-019-0539-4.\r\n\r\n\r\n[3] Johnson ECB, Dammer EB, Duong DM, Ping L, Zhou M, Yin L, et al. Large-scale proteomic analysis of Alzheimerâ€™s disease brain and cerebrospinal fluid reveals early changes in energy metabolism associated with microglia and astrocyte activation. Nature Medicine 2020;26:769â€“80. https://doi.org/10.1038/s41591-020-0815-6.\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2021-07-16T11:49:57-07:00"
    },
    {
      "path": "pathway-enrichment.html",
      "title": "Pathway Enrichment Analysis",
      "description": "This script performs pathway enrichment analyses using the Gene Ontology and Reactome databases.\n",
      "author": [
        {
          "name": {},
          "url": "https://www.github.com/ayushnoori"
        }
      ],
      "contents": "\r\n\r\nContents\r\nDependencies\r\nRead Data\r\nParse Pathway Enrichment Results\r\nAggregate Annotated Pathways\r\n\r\nDependencies\r\nLoad requisite packages. Note that the tibble package is not loaded (to preempt namespace conflicts) but the tibble::add_row function is explicitly called.\r\nThis script also uses my personal utilities package brainstorm, which can be downloaded via devtools::install_github(\"ayushnoori/brainstorm\").\r\n\r\n\r\n# data manipulation\r\nlibrary(data.table)\r\nlibrary(purrr)\r\nlibrary(magrittr)\r\n\r\n# string operations\r\nlibrary(stringr)\r\n\r\n# Excel manipulation\r\nlibrary(openxlsx)\r\n\r\n# data visualization\r\nlibrary(ggplot2)\r\nlibrary(ggpubr)\r\n\r\n# utility functions\r\nlibrary(brainstorm)\r\n\r\n\r\n\r\nNote that directories are relative to the R project path.\r\n\r\n\r\n# set directories\r\nddir = file.path(\"Data\", \"2 - Pathway Enrichment Analysis\")\r\ndir2 = file.path(\"Results\", \"2 - Pathway Enrichment Analysis\")\r\n\r\n\r\n\r\nRead Data\r\nRead data, then input the gene symbols to http://www.gsea-msigdb.org/gsea/msigdb/annotate.jsp. Compute overlaps separately against the Gene Ontology (GO:BP: GO biological process, GO:CC: GO cellular component, GO:MF: GO molecular function) [1,2] and Reactome (CP:REACTOME: Reactome gene sets) [3] databases available from the Molecular Signatures Database [4]. For each analysis, show the top 100 gene sets with FDR q-value less than 1 (i.e., no q-value cutoff). Place output files in the Data/2 - Pathway Enrichment Analysis directory.\r\n\r\n\r\n# read data\r\nmarkers = fread(file.path(\"Data\", \"ADRA Protein Set.csv\"))\r\n# cat(markers[, Symbol])\r\n\r\n\r\n\r\nRead MSigDB mapping file (version 7.2), which was downloaded as an XML file from https://data.broadinstitute.org/gsea-msigdb/msigdb/release/7.2/msigdb_v7.2.xml, parsed in Excel, and filtered for GO/Reactome pathways only.\r\n\r\n\r\n# read mapping file\r\nmapDB = fread(file.path(ddir, \"MSigDB Mapping v7.3.csv\")) %>%\r\n  .[, .(STANDARD_NAME, EXACT_SOURCE, MEMBERS_SYMBOLIZED, MEMBERS)]\r\nsetnames(mapDB, c(\"Pathway\", \"ID\", \"Symbol\", \"ENTREZ\"))\r\n\r\n\r\n\r\nParse Pathway Enrichment Results\r\nDefine Excel styles for workbook object.\r\n\r\n\r\n# header style\r\nhs = createStyle(fontColour = \"#FAF3DD\", fgFill = \"#337CA0\", fontName = \"Arial Black\", halign = \"center\", valign = \"center\", textDecoration = \"Bold\", border = \"Bottom\", borderStyle = \"thick\", fontSize = 14)\r\n\r\n# row style #1\r\nr1 = createStyle(fontColour = \"#363635\", fgFill = \"#FAF3DD\", fontName = \"Arial\", fontSize = 10)\r\n\r\n# row style #2\r\nr2 = createStyle(fontColour = \"#363635\", fgFill = \"#C4E4E9\", fontName = \"Arial\", fontSize = 10)\r\n\r\n# subheader style\r\nsh = createStyle(fontColour = \"#363635\", fgFill = \"#FFA69E\", fontName = \"Arial\", textDecoration = \"Bold\", border = \"TopBottom\", borderStyle = \"thick\")\r\n\r\n\r\n\r\nDefine function to add sheet to workbook, where clus is a vector of cluster labels, sheet is the worksheet name, and header is the vector of header indices.\r\n\r\n\r\nadd_sheet = function(datWB, clus, sheet, header, wb) {\r\n  \r\n  # add worksheet\r\n  addWorksheet(wb, sheetName = sheet)\r\n  writeDataTable(wb, sheet, x = datWB, tableStyle = \"TableStyleMedium15\", headerStyle = hs, bandedRows = FALSE)\r\n  setColWidths(wb, sheet, cols = 1:10, widths = c(\"auto\", 60, 8, 8, 8, 16, 16, 20, 20, 200))\r\n  freezePane(wb, sheet, firstRow = TRUE, firstCol = FALSE)\r\n  \r\n  # add styling\r\n  even = clus %% 2 == 0; even[is.na(even)] = FALSE\r\n  addStyle(wb, sheet, r1, rows = which(even) + 1, cols = 1:10, gridExpand = T)\r\n  addStyle(wb, sheet, r2, rows = which(!even) + 1, cols = 1:10, gridExpand = T)\r\n  addStyle(wb, sheet, sh, rows = header + 1, cols = 1:10, gridExpand = T)\r\n  \r\n}\r\n\r\n\r\n\r\nParse, cluster, and tabulate pathway enrichment results. The similarity matrix is created by computing the Jaccard similarity coefficient, then converted to Jaccard distance by subtracting from 1.\r\n\r\n\r\n# function to compute Jaccard similarity coefficient\r\njaccard = function(a, b) {return(length(intersect(a,b))/length(union(a, b)))}\r\n\r\n# read pathway enrichment results\r\nparse_pathways = function(fname, wb) {\r\n  \r\n  # read file\r\n  dat = fread(file.path(ddir, fname))\r\n  setnames(dat, c(\"Pathway\", \"K\", \"Description\", \"k\", \"Ratio\", \"p\", \"q\"))\r\n  \r\n  # merge with mapping, clean pathway names, get member list\r\n  dat = merge(dat, mapDB, by = \"Pathway\", all.x = TRUE) %>%\r\n    .[, Pathway := gsub(\"_\", \" \", Pathway)] %>%\r\n    .[, Pathway := sub(\".*? \", \"\", Pathway)] %>%\r\n    .[, Members := strsplit(ENTREZ, \",\")]\r\n  \r\n  # create pairwise similarity matrix using Jaccard index\r\n  sim = dat[, Members] %>% outer(., ., FUN = Vectorize(jaccard))\r\n  rownames(sim) = dat[, ID]; colnames(sim) = dat[, ID]\r\n  \r\n  # specify number of clusters\r\n  nclust = 15\r\n  # h = 0.95\r\n  \r\n  # convert to dissimilarity matrix, then perform hierarchical clustering\r\n  pclust = as.dist(1 - sim) %>%\r\n    hclust() %>%\r\n    cutree(k = nclust) %>%\r\n    # cutree(h = 0.95) %>%\r\n    data.table(ID = names(.), Cluster = .)\r\n  \r\n  # get number of clusters\r\n  # nclust = pclust[, length(unique(Cluster))]\r\n  # print(nclust)\r\n  \r\n  # merge with cluster, then group by cluster and order by q-value\r\n  dat = merge(dat, pclust, by = \"ID\", all.x = TRUE) %>%\r\n    .[order(Cluster, q), ] %>%\r\n    .[, .(ID, Pathway, K, k, Ratio, p, q, Cluster, Symbol, ENTREZ, Description)]\r\n  \r\n  # rename columns for Excel workbook\r\n  datWB = copy(dat)\r\n  setnames(datWB, c(\"ID\", \"Pathway\", \"K (Genes in Pathway)\", \"k (Genes in Overlap)\", \"k/K\", \"p-value\", \"FDR q-value\", \"Cluster\", \"Symbol\", \"ENTREZ\", \"Description\"))\r\n  header = datWB[, which(!duplicated(Cluster))] + 0:(nclust - 1)\r\n  \r\n  # add rows for manual annotatioN\r\n  for (z in header) {\r\n    datWB = tibble::add_row(datWB, .before = z)\r\n    datWB[z, ID := paste0(\"Pathway #\", datWB[z + 1, \"Cluster\"])]\r\n  }\r\n  \r\n  # get cluster and sheet name, add to workbook\r\n  clus = datWB[, Cluster]; datWB[, Cluster := NULL]\r\n  sheet = fname %>% gsub(\"\\\\s+Enrichment\\\\.csv$\", \"\", .)\r\n  add_sheet(datWB, clus, sheet, header, wb)\r\n  \r\n  # return original data\r\n  return(dat)\r\n  \r\n}\r\n\r\n\r\n\r\nMap pathway_results function over each analysis (i.e., GO: BP, GO: CC, GO: MF, and Reactome).\r\n\r\n\r\n# get file names\r\nfiles = list.files(path = ddir, pattern = \"Enrichment\\\\.csv$\")\r\n\r\n# create workbook object\r\ngrpWB = createWorkbook()\r\n\r\n# map over file names\r\npathways = map(files, ~parse_pathways(.x, grpWB))\r\n\r\n\r\n\r\nSave workbook object.\r\n\r\n\r\n# define file paths\r\nraw = file.path(dir2, \"Pathway Enrichment Analysis Raw.xlsx\")\r\nannot = file.path(dir2, \"Pathway Enrichment Analysis Annotated.xlsx\")\r\n\r\n# save workbooks\r\nsaveWorkbook(grpWB, raw, overwrite = TRUE)\r\nif(!file.exists(annot)) { file.copy(raw, annot) }\r\n\r\n\r\n\r\nAggregate Annotated Pathways\r\nComplete pathway annotations by manually editing the file Pathway Enrichment Analysis Annotated.xlsx. After annotations are complete, execute the following chunks which compute cluster statistics.\r\n\r\n\r\ncompute_cluster = function(sheet) {\r\n  \r\n  # read data\r\n  dat = read.xlsx(annot, sheet = sheet, check.names = TRUE) %>% as.data.table()\r\n  setnames(dat,  c(\"ID\", \"Pathway\", \"K\", \"k\", \"Ratio\", \"p\", \"q\",\r\n                   \"Symbol\", \"ENTREZ\", \"Description\"))\r\n  \r\n  # get header indices\r\n  header = dat[, which(is.na(Description))]\r\n  \r\n  # extract cluster labels\r\n  clus = dat[header, .(ID, Pathway)]\r\n  nclus = c(header[-1], nrow(dat) + 1) - (header + 1)\r\n  \r\n  # re-create cluster labels\r\n  dat = dat[-header, ][, Cluster := rep(clus$ID, nclus)]\r\n  \r\n  # compute cluster statistics\r\n  clusdat = dat[, .(Ratio = sum(k)/sum(K), logQ = mean(-log10(q))), by = Cluster]\r\n  clus = merge(clus, clusdat, by.x = \"ID\", by.y = \"Cluster\")[, Database := sheet]\r\n  \r\n  return(clus)\r\n  \r\n}\r\n\r\n\r\n\r\nMap compute_cluster function over each sheet of the annotations workbook (i.e., GO: BP, GO: CC, GO: MF, and Reactome) to compute cluster statistics.\r\n\r\n\r\n# get file names\r\nsheets = getSheetNames(annot)\r\n\r\n# map over file names\r\nclusters = map_dfr(sheets, compute_cluster)\r\n\r\n# refactor cluster database labels and order by -log10(FDR q-value)\r\nclusters = clusters %>%\r\n  .[, ID := NULL] %>%\r\n  .[, Database := factor(Database, levels = c(\"GO BP\", \"GO CC\", \"GO MF\", \"Reactome\"), labels = c(\"GO: Biological Process\", \"GO: Cellular Component\", \"GO: Molecular Function\", \"Reactome\"))] %>%\r\n  .[order(Database, logQ), ]\r\n\r\n\r\n\r\nFunction to plot pathway data in a barplot for each enrichment analysis (i.e., for each database). Note that facet_wrap is used for visual purposes only. Each plot created has a single facet.\r\n\r\n\r\nplot_pathways = function(datDB, DB) {\r\n  \r\n  datDB[, Pathway := factor(Pathway, levels = Pathway)]\r\n\r\n  p = ggplot(datDB, aes(x = Pathway, y = logQ))+ # fill = Ratio\r\n    geom_col() +\r\n    coord_flip() +\r\n    # scale_fill_gradient(low=\"#FFD166\", high=\"#A63446\") +\r\n    facet_wrap(Database ~ ., scales = \"free\", ncol = 1) +\r\n    # labs(fill = \"Gene Ratio\") + \r\n    scale_y_continuous(limits = c(0, NA), expand = expansion(mult = c(0, 0.05))) +\r\n    theme_light() +\r\n    theme(plot.title = element_text(size = 16, color = \"black\", face = \"bold\", hjust = 0.5),\r\n          axis.title.x = element_blank(), axis.title.y = element_blank(),\r\n          legend.title = element_text(face = \"bold\"),\r\n          strip.text = element_text(size=12, color = \"black\", face=\"bold\"),\r\n          strip.background = element_rect(color=NA, fill=\"#D9D9D9\", size=1, linetype=\"solid\"))\r\n  \r\n  return(p)\r\n\r\n}\r\n\r\n\r\n\r\nApply function over each database to create aggregated plot.\r\n\r\n\r\n# map over each database\r\ncplots = imap(split(clusters, by = \"Database\"), plot_pathways) %>%\r\n  ggarrange(plotlist = ., ncol = 1, nrow = 4, align = \"hv\") %>%\r\n  annotate_figure(bottom = text_grob(bquote(bold(-log[10]*'(FDR '*bolditalic(q)*'-value)')),\r\n                                     size = 16, color = \"black\", hjust = 0))\r\n\r\n# save figure\r\nggsave(file.path(dir2, \"Pathway Enrichment Analysis Barplot.pdf\"), cplots, height = 16, width = 12)\r\n\r\n\r\n\r\n\r\n\r\n\r\n[1] Ashburner M, Ball CA, Blake JA, Botstein D, Butler H, Cherry JM, et al. Gene Ontology: Tool for the unification of biology. Nature Genetics 2000;25:25â€“9. https://doi.org/10.1038/75556.\r\n\r\n\r\n[2] The Gene Ontology Consortium. The Gene Ontology Resource: 20 years and still GOing strong. Nucleic Acids Research 2019;47:D330â€“8. https://doi.org/10.1093/nar/gky1055.\r\n\r\n\r\n[3] Jassal B, Matthews L, Viteri G, Gong C, Lorente P, Fabregat A, et al. The Reactome Pathway Knowledgebase. Nucleic Acids Research 2020;48:D498â€“503. https://doi.org/10.1093/nar/gkz1031.\r\n\r\n\r\n[4] Liberzon A, Subramanian A, Pinchback R, ThorvaldsdÃ³ttir H, Tamayo P, Mesirov JP. Molecular signatures database (MSigDB) 3.0. Bioinformatics 2011;27:1739â€“40. https://doi.org/10.1093/bioinformatics/btr260.\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2021-07-16T11:50:05-07:00"
    },
    {
      "path": "tf-enrichment.html",
      "title": "Transcription Factor Enrichment Analysis",
      "description": "This script performs transcription factor analyses using TFEA.ChIP and Enrichr.\n",
      "author": [
        {
          "name": {},
          "url": "https://www.github.com/ayushnoori"
        }
      ],
      "contents": "\r\n\r\nContents\r\nDependencies\r\nRead Data\r\nTFEA.ChIP Analysis\r\nTFEA.ChIP Volcano Plot\r\nEnrichr Analysis\r\nEnrichr Plot\r\n\r\nDependencies\r\nLoad requisite packages. This script uses my personal utilities package brainstorm, which can be downloaded via devtools::install_github(\"ayushnoori/brainstorm\").\r\n\r\n\r\n# data manipulation\r\nlibrary(data.table)\r\nlibrary(purrr)\r\nlibrary(magrittr)\r\n\r\n# TFEA package\r\nlibrary(TFEA.ChIP)\r\n\r\n# access Enrichr API\r\nlibrary(httr)\r\nlibrary(rjson)\r\n\r\n# Excel manipulation\r\nlibrary(openxlsx)\r\n\r\n# string manipulation\r\nlibrary(stringr)\r\n\r\n# data visualization\r\nlibrary(ggplot2)\r\nlibrary(ggpubr)\r\nlibrary(plotly)\r\nlibrary(htmlwidgets)\r\nlibrary(RColorBrewer)\r\n\r\n# utility functions\r\nlibrary(brainstorm)\r\n\r\n\r\n\r\nNote that directories are relative to the R project path.\r\n\r\n\r\n# set directories\r\nddir = file.path(\"Data\", \"3 - Transcription Factor Enrichment Analysis\")\r\ndir3 = file.path(\"Results\", \"3 - Transcription Factor Enrichment Analysis\")\r\n\r\n\r\n\r\nRead Data\r\nRead ADRA protein set and load ChIP-Seq experiment data [1â€“4].\r\n\r\n\r\n# read data\r\ndat = fread(file.path(\"Data\", \"ADRA Protein Set.csv\"))\r\n\r\n# load ChIP-Seq experiment data\r\nload(file.path(ddir, \"ReMap+GH_doubleElite.Rdata\"))\r\nset_user_data(MetaData, Mat01)\r\n\r\n\r\n\r\nTFEA.ChIP Analysis\r\nPerform Transcription Factor Enrichment Analysis (TFEA) using the TFEA.ChIP package [5]. As a control list is not provided, use all human genes NOT in the ADRA marker set as the control.\r\n\r\n\r\n# convert ADRA gene symbols to ENTREZ\r\nentrez = GeneID2entrez(gene.IDs = dat[, Symbol])\r\n\r\n# compute contingency matrices\r\nCM = contingency_matrix(entrez)\r\npval = getCMstats(CM) %>% as.data.table()\r\n\r\n# compute confidence intervals\r\nCI = map(CM, ~fisher.test(.x, conf.int = TRUE, conf.level = 0.95)$conf.int) %>%\r\n  { data.table(Accession = names(.), CI.left = map(., 1), CI.right = map(., 2)) }\r\n\r\n# merge with confidence intervals\r\npval = merge(pval, CI, by = \"Accession\", all.x = TRUE)[order(-abs(distance)), ]\r\n\r\n# write to Excel file\r\nwrite.xlsx(pval, file.path(dir3, \"TFEA Association Test.xlsx\"), asTable = TRUE, tableStyle = \"TableStyleMedium19\")\r\n\r\n\r\n\r\nTFEA.ChIP Volcano Plot\r\nSelect transcription factors to highlight and define colors.\r\n\r\n\r\n# identify top TFs\r\ntopTFs = summary(as.factor(pval[1:200, TF]))\r\nprint(topTFs[order(-topTFs)][1:5])\r\n\r\n# select top TFs\r\nTF = c(\"CTCF\", \"ESR1\")\r\nnames(TF) = TF\r\n\r\n# select plotting colors\r\nTFcol = c(\"#00FFD9\", \"#FF006F\")\r\n\r\n\r\n\r\nCreate interactive volcano plot of transcription factor enrichment analysis results.\r\n\r\n\r\n# create volcano plot\r\nCMplot = plot_CM(pval, plot_title = \"\", specialTF = TF, TF_colors = TFcol)\r\n\r\n# create axis sequences\r\nxseq = pval[, log10.adj.pVal] %>% { seq(min(., na.rm = TRUE), max(., na.rm = TRUE), by = 0.1) }\r\nyseq = pval[, log2.OR] %>% { seq(min(., na.rm = TRUE), max(., na.rm = TRUE), by = 0.1) }\r\n\r\n# edit volcano plot\r\nCMplot = CMplot %>%\r\n  \r\n  # add p-value threshold line\r\n  add_lines(x = -log10(0.05), y = yseq, line = list(dash=\"dash\", width = 1.5, color=\"red\"), inherit = FALSE, hoverinfo = \"none\", name = \"P-Value < 0.05\", visible = \"legendonly\") %>%\r\n  \r\n  # add OR threshold lines\r\n  add_lines(x = xseq, y = log2(1.5), line = list(dash=\"dash\", width = 1.5, color=\"blue\"), inherit = FALSE, hoverinfo = \"none\", name = \"OR > 1.5\", visible = \"legendonly\") %>%\r\nadd_lines(x = xseq, y = -log2(1.5), line = list(dash=\"dash\", width = 1.5, color=\"blue\"), inherit = FALSE, hoverinfo = \"none\", name = \"OR < -1.5\", visible = \"legendonly\") %>%\r\n  \r\n  # add axis labels\r\nlayout(xaxis = list(title = \"-Log<sub>10<\/sub> Adjusted P-Value\"), yaxis = list(title = \"Log<sub>2<\/sub> Odds Ratio\"))  %>%\r\n  \r\n  # configure SVG output\r\n  config(toImageButtonOptions = list(format = \"svg\", filename = \"TFEA Plot SVG\", width = 2000, height = 1200))\r\n\r\n# save figure\r\nhtmlwidgets::saveWidget(CMplot, file.path(dir3, \"TFEA Plot.html\"))\r\nsaveRDS(CMplot, file.path(dir3, \"TFEA Plotly Object.rds\"))\r\n\r\n\r\n\r\nCreate enhanced, static volcano plot of transcription factor enrichment analysis results.\r\n\r\n\r\n# prepare data\r\npval_vp = copy(pval) %>%\r\n  .[, Highlight := TF] %>%\r\n  .[!(Highlight %in% c(\"CTCF\", \"ESR1\")), Highlight := \"Other\"]\r\n\r\n# plot data\r\nvp = ggplot(pval_vp, aes(x = log2.OR, y = log10.adj.pVal, fill = Highlight)) +\r\n  geom_hline(yintercept = 0, color = \"black\", size = 0.3) +\r\n  geom_vline(xintercept = -1.99, color = \"black\", size = 0.3) +\r\n  geom_point(alpha = 0.3, size = 1.2, shape = 21, stroke = 0) +\r\n  scale_fill_manual(\"\", values = c(\"#01CB5F\", \"#F17F29\", \"#687278\")) +\r\n  geom_point(data = pval[TF == \"CTCF\"], fill = \"#01CB5F\", size = 1.2, shape = 21, stroke = 0) +\r\n  geom_point(data = pval[TF == \"ESR1\"], fill = \"#F17F29\", size = 1.2, shape = 21, stroke = 0) +\r\n  geom_hline(yintercept = -log10(0.05), linetype=\"dashed\", color = \"#EF476F\", size = 0.3) +\r\n  geom_vline(xintercept = -log2(1.5), linetype=\"dashed\", color = \"#3066BE\", size = 0.3) +\r\n  geom_vline(xintercept = log2(1.5), linetype=\"dashed\", color = \"#3066BE\", size = 0.3) +\r\n  coord_cartesian(xlim = c(-1.99, 1.99), ylim = c(-0.01, 1.99), expand = FALSE) +\r\n  xlab(bquote(bold(log[2]*' Fold-Change'))) +\r\n  ylab(bquote(bold(-log[10]*' FDR '*bolditalic(p)*'-value'))) +\r\n  theme_light() +\r\n  theme(legend.text = element_text(size = 10, face = \"bold\"),\r\n        legend.position = c(0.1, 0.93),\r\n        legend.background = element_rect(fill = NA, color = NA),\r\n        axis.ticks = element_line(color = \"black\", size = 0.3),\r\n        panel.border = element_blank())\r\n\r\n# save plot\r\n# ggsave(file.path(dir3, \"TFEA Volcano Plot.pdf\"), vp, width = 8, height = 5.5)\r\nggsave(file.path(dir3, \"TFEA Volcano Plot.svg\"), vp, width = 8, height = 5.5)\r\nggsave(file.path(dir3, \"TFEA Volcano Plot.pdf\"), vp, width = 8, height = 5.5)\r\n\r\n\r\n\r\nEnrichr Analysis\r\nPerform TFEA using the Enrichr API [6].\r\n\r\n\r\n# define API call parameters\r\nmy_genes = gsub(\"^\\\\s+|\\\\s+$\", \"\", dat[, Symbol])\r\nmy_library = \"ENCODE_and_ChEA_Consensus_TFs_from_ChIP-X\"\r\nmy_description = \"ADRA Marker Set\"\r\n\r\n\r\n\r\nFunction for API call. This function was adapted from the Python scripts provided in the Enrichr API documentation here.\r\n\r\n\r\nenrichr_API = function(genes, description, library) {\r\n  \r\n  # create API call to add gene list\r\n  add_url = \"http://amp.pharm.mssm.edu/Enrichr/addList\"\r\n  genes_str = paste(genes, collapse=\"\\n\")\r\n  payload = list(list = genes_str, description = description)\r\n  \r\n  # make and parse API call\r\n  add_request = httr::POST(url = add_url, body = payload)\r\n  add_response = httr::content(add_request, as = \"text\", encoding = \"UTF-8\") %>% fromJSON()\r\n  \r\n  # wait before next call\r\n  Sys.sleep(0.5)\r\n  \r\n  # create URL for next API call to calculate enrichment\r\n  enrich_url = paste0(\"http://amp.pharm.mssm.edu/Enrichr/enrich\", \"?userListId=\",\r\n                      add_response$userListId, \"&backgroundType=\", library)\r\n  \r\n  # make and parse next API call\r\n  request = httr::GET(url = enrich_url)\r\n  response = httr::content(request, as = \"text\", encoding = \"UTF-8\") %>% fromJSON() %>% .[[1]]\r\n  \r\n  # convert to data.table\r\n  convDT = function(res) { res[[6]] = toString(res[[6]]); return(res)  }\r\n  response = map(response, convDT) %>% rbindlist()\r\n  setnames(response, c(\"Rank\", \"Term\", \"p.value\", \"z.score\", \"combined.score\", \"Genes\", \"adj.p.value\", \"old.p.value\", \"old.adj.p.value\"))\r\n  \r\n  # calculate -log10(adj. p-value), then filter\r\n  response[, log.adj.p := -log10(adj.p.value)]\r\n  response = response[, .(Term, p.value, adj.p.value, log.adj.p, z.score, combined.score, Genes)]\r\n  \r\n  # return response object\r\n  return(response)\r\n\r\n}\r\n\r\n\r\n\r\nMake API call to calculate enrichment.\r\n\r\n\r\n# make API call\r\nenrichr = enrichr_API(my_genes, my_description, my_library)\r\n\r\n# write to Excel file\r\nwrite.xlsx(enrichr, file.path(dir3, \"Enrichr Results.xlsx\"), asTable = TRUE, tableStyle = \"TableStyleMedium19\")\r\n\r\n\r\n\r\nEnrichr Plot\r\nFunction to plot Enrichr results.\r\n\r\n\r\nplot_enrichr = function(enrichr_results, library = NULL) {\r\n  \r\n  # for TFEA only\r\n  enrichr_results[, Term := word(Term, 1)]\r\n  \r\n  # select top TFs\r\n  enrichr_results = enrichr_results[order(-log.adj.p), ][1:10, ]\r\n  enrichr_results[, Term := factor(Term, levels = rev(Term))]\r\n  \r\n  # create barplot\r\n  p = ggplot(enrichr_results, aes(x = Term, y = log.adj.p, fill = log.adj.p))+\r\n    geom_col() +\r\n    coord_flip() +\r\n    geom_hline(yintercept = -log10(0.05), linetype = \"dashed\", color = \"black\") +\r\n    geom_text(x = 1.7, y = -log10(0.05) + 0.03, label = \"italic(p)*'-value < 0.05'\", angle = 270, size = 2.5, parse = TRUE) +\r\n    scale_fill_gradient(low=\"#FFD166\", high=\"#A63446\") +\r\n    scale_y_continuous(limits = c(0, NA), expand = expansion(mult = c(0, 0.05))) +\r\n    theme_light() +\r\n    theme(plot.title = element_text(size = 16, color = \"black\", face = \"bold\", hjust = 0.5),\r\n          axis.title.x = element_blank(), axis.title.y = element_blank(),\r\n          legend.position = \"none\",\r\n          strip.text = element_text(size=12, color = \"black\", face=\"bold\"),\r\n          strip.background = element_rect(color=NA, fill=\"#D9D9D9\", size=1, linetype=\"solid\"))\r\n  \r\n  if(!is.null(library)) {\r\n    enrichr_results[, Library := library]\r\n    p = p + facet_wrap(Library ~ ., scales = \"free\", ncol = 1)\r\n  } else {\r\n    p = p + ylab(bquote(bold(-log[10]*'(adj. '*bolditalic(p)*'-value)'))) + theme(axis.title.x = element_text(size = 14, color = \"black\"))\r\n  }\r\n  \r\n  return(p)\r\n\r\n}\r\n\r\n\r\n\r\nSave plots for multiple Enrichr libraries. To create plots of multiple Enrichr results, use map as plot_enrichr(enrichr, library_name), then use ggarrange(plotlist = ., ncol = 1, align = \"hv\") to create composite figure.\r\n\r\n\r\ncplots = plot_enrichr(enrichr) # %>% annotate_figure(bottom = text_grob(bquote(bold(-log[10]*'(adj. '*bolditalic(p)*'-value)')), size = 14, color = \"black\", hjust = 0))\r\n\r\n# save figure\r\nggsave(file.path(dir3, \"Enrichr Barplot.pdf\"), cplots, height = 4, width = 12)\r\n\r\n\r\n\r\n\r\n\r\n\r\n[1] Lachmann A, Xu H, Krishnan J, Berger SI, Mazloom AR, Maâ€™ayan A. ChEA: Transcription factor regulation inferred from integrating genome-wide ChIP-X experiments. Bioinformatics (Oxford, England) 2010;26:2438â€“44. https://doi.org/10.1093/bioinformatics/btq466.\r\n\r\n\r\n[2] Dunham I, Kundaje A, Aldred SF, Collins PJ, Davis CA, Doyle F, et al. An integrated encyclopedia of DNA elements in the human genome. Nature 2012;489:57â€“74. https://doi.org/10.1038/nature11247.\r\n\r\n\r\n[3] Fishilevich S, Nudel R, Rappaport N, Hadar R, Plaschkes I, Iny Stein T, et al. GeneHancer: Genome-wide integration of enhancers and target genes in GeneCards. Database 2017;2017. https://doi.org/10.1093/database/bax028.\r\n\r\n\r\n[4] ChÃ¨neby J, Gheorghe M, Artufel M, Mathelier A, Ballester B. ReMap 2018: An updated atlas of regulatory regions from an integrative analysis of DNA-binding ChIP-seq experiments. Nucleic Acids Research 2018;46:D267â€“75. https://doi.org/10.1093/nar/gkx1092.\r\n\r\n\r\n[5] Puente-Santamaria L, Wasserman WW, Del Peso L. TFEA.ChIP: A tool kit for transcription factor binding site enrichment analysis capitalizing on ChIP-seq datasets. Bioinformatics (Oxford, England) 2019;35:5339â€“40. https://doi.org/10.1093/bioinformatics/btz573.\r\n\r\n\r\n[6] Kuleshov MV, Jones MR, Rouillard AD, Fernandez NF, Duan Q, Wang Z, et al. Enrichr: A comprehensive gene set enrichment analysis web server 2016 update. Nucleic Acids Research 2016;44:W90â€“97. https://doi.org/10.1093/nar/gkw377.\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2021-07-16T11:50:16-07:00"
    }
  ],
  "collections": []
}
